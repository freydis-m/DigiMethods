{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise W7D1: Review and Putting it All Together\n",
    "\n",
    "This exercise aims to draw together the topics we have covered in the _Base Camp_ portion of the Digital Methods class. At the end of the exercise, you should have a `DataFrame` with each row containing information on a Twitter account including their tweets, friends, followers, hashtags and mentions as well as some descriptive statistics.\n",
    "\n",
    "You will be able to reuse and modify this code for the second half of digital methods to download and analyze tweets for your projects. So, this exercise should provide you with a solid review of different things we have learned and help you for the the rest of the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "print(tweepy.__version__)\n",
    "\n",
    "from AppCred import CONSUMER_KEY, CONSUMER_SECRET\n",
    "from AppCred import ACCESS_TOKEN, ACCESS_TOKEN_SECRET\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1. Identify a topic, authenticate, and get data.** First, identify a topic of interest to you and think about a keyword or hashtag capturing the topic. Possible topics could be Corona or Climate, but you are welcome to choose something else. Then load the `tweepy` module and use the built-in functionality to `search` Twitter for your keyword or hashtag. Create a variable that contains the data returned by your search.\n",
    "\n",
    "See [here](http://docs.tweepy.org/en/latest/api.html#help-methods) for more information about the `search` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "demdeb_tweets = api.search(q = \"DemDebate\", since=\"2020-03-15\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an object containing a number of tweets pertaining to our topic of interest. As you might remember, by default the Twitter API returns the data to us in JSON format. Now that we know about the elegance and beauty of `DataFrames`, we would prefer to work with that format of data rather than a dictionary-style JSON. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2. Turn raw API data into a DataFrame.** Your search returned a set of tweets about your chosen topic. Construct a `DataFrame` from your Twitter search object of the people who are tweeting about that topic that, at minimum, contains the unique `screen_names`, `followers_count`, `friends_count`, and `statuses_count` returned from your search. \n",
    "\n",
    "There are a number of ways to do this so you might want to review how to construct `DataFrames` (W6D1-Demo). You may also want to review navigating JSON objects (W4D2-Exercise_solutions). Also, your returned data might include the same account multiple times, so you will want to make sure that you are listing the account only once in your `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = []\n",
    "tweet_text = []\n",
    "truncated =[]\n",
    "post_date =[]\n",
    "followers=[]\n",
    "\n",
    "for tweet in demdeb_tweets:\n",
    "    username = tweet._json[\"user\"][\"screen_name\"]\n",
    "    usernames.append(username)\n",
    "    \n",
    "    text = tweet._json[\"text\"]\n",
    "    tweet_text.append(text)\n",
    "    \n",
    "    trunc = tweet._json[\"truncated\"]\n",
    "    truncated.append(trunc)\n",
    "\n",
    "    posted_on = tweet._json[\"created_at\"]\n",
    "    post_date.append(posted_on)\n",
    "\n",
    "    \n",
    "    followercount = tweet._json[\"user\"][\"followers_count\"]\n",
    "    followers.append(followercount)\n",
    "    \n",
    "\n",
    "demdeb_mar15 = {\"username\": usernames,\n",
    "               \"text\": tweet_text,\n",
    "               \"truncated?\": truncated,\n",
    "               \"date posted\": post_date,\n",
    "               \"follower count\": followers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated?</th>\n",
       "      <th>date posted</th>\n",
       "      <th>follower count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sonyaliloquy</td>\n",
       "      <td>RT @GottaBernNow: To be clear:\\nWe are not emp...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:13:19 +0000 2020</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Electricknight5</td>\n",
       "      <td>RT @MarkDice: The Bernie vs Biden #DemDebate i...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:13:08 +0000 2020</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>DireChange2</td>\n",
       "      <td>RT @RBReich: If Biden gets the nomination, not...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:13:03 +0000 2020</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FuqdInTheUSA</td>\n",
       "      <td>RT @sunrisemvmt: .@JoeBiden just repeated a sm...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:51 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Gary04337542</td>\n",
       "      <td>RT @TeamTrump: While Sleepy Joe and Crazy Bern...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:47 +0000 2020</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>KittyCat11231</td>\n",
       "      <td>RT @NaomiAKlein: Let this sink in. Understand ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:45 +0000 2020</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>DeploraBIL</td>\n",
       "      <td>RT @HOLYSMKES: #DemDebate recap https://t.co/Y...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:44 +0000 2020</td>\n",
       "      <td>6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>MoveOnTC</td>\n",
       "      <td>RT @OurRevolution: Joe - LYING  to the America...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:33 +0000 2020</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>ColejrJs</td>\n",
       "      <td>RT @RBReich: Your #DemDebate reminder that Med...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:22 +0000 2020</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>MelindaTanner16</td>\n",
       "      <td>RT @SethAbramson: RETWEET if you too would rat...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:21 +0000 2020</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>scott_websig</td>\n",
       "      <td>RT @TrumpWarRoom: President Trump: \"If you lik...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:20 +0000 2020</td>\n",
       "      <td>3093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ChasPalacios</td>\n",
       "      <td>RT @People4Bernie: Joe: You get rid of the nin...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:06 +0000 2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>fathanks</td>\n",
       "      <td>RT @CDRosa: Here's Joe Biden praising China's ...</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Mar 17 13:12:01 +0000 2020</td>\n",
       "      <td>2504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           username                                               text  \\\n",
       "0      sonyaliloquy  RT @GottaBernNow: To be clear:\\nWe are not emp...   \n",
       "1   Electricknight5  RT @MarkDice: The Bernie vs Biden #DemDebate i...   \n",
       "2       DireChange2  RT @RBReich: If Biden gets the nomination, not...   \n",
       "3      FuqdInTheUSA  RT @sunrisemvmt: .@JoeBiden just repeated a sm...   \n",
       "4      Gary04337542  RT @TeamTrump: While Sleepy Joe and Crazy Bern...   \n",
       "5     KittyCat11231  RT @NaomiAKlein: Let this sink in. Understand ...   \n",
       "6        DeploraBIL  RT @HOLYSMKES: #DemDebate recap https://t.co/Y...   \n",
       "7          MoveOnTC  RT @OurRevolution: Joe - LYING  to the America...   \n",
       "8          ColejrJs  RT @RBReich: Your #DemDebate reminder that Med...   \n",
       "9   MelindaTanner16  RT @SethAbramson: RETWEET if you too would rat...   \n",
       "10     scott_websig  RT @TrumpWarRoom: President Trump: \"If you lik...   \n",
       "11     ChasPalacios  RT @People4Bernie: Joe: You get rid of the nin...   \n",
       "12         fathanks  RT @CDRosa: Here's Joe Biden praising China's ...   \n",
       "\n",
       "    truncated?                     date posted  follower count  \n",
       "0        False  Tue Mar 17 13:13:19 +0000 2020             434  \n",
       "1        False  Tue Mar 17 13:13:08 +0000 2020             879  \n",
       "2        False  Tue Mar 17 13:13:03 +0000 2020              18  \n",
       "3        False  Tue Mar 17 13:12:51 +0000 2020               0  \n",
       "4        False  Tue Mar 17 13:12:47 +0000 2020              24  \n",
       "5        False  Tue Mar 17 13:12:45 +0000 2020              50  \n",
       "6        False  Tue Mar 17 13:12:44 +0000 2020            6914  \n",
       "7        False  Tue Mar 17 13:12:33 +0000 2020             249  \n",
       "8        False  Tue Mar 17 13:12:22 +0000 2020             276  \n",
       "9        False  Tue Mar 17 13:12:21 +0000 2020              11  \n",
       "10       False  Tue Mar 17 13:12:20 +0000 2020            3093  \n",
       "11       False  Tue Mar 17 13:12:06 +0000 2020               1  \n",
       "12       False  Tue Mar 17 13:12:01 +0000 2020            2504  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "demdeb_mar = pd.DataFrame(demdeb_mar15)\n",
    "\n",
    "demdeb_mar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our neat `DataFrame` we can now easily find out details about the data we collected from Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3. Get information about our data.** Use the `print` function and string operations to make Python tell you in plain language: a) How many unique accounts there are in your data, b) what the name of the _last_ account in your data is, and c) what the sum of followers is for all accounts in your data. That is make Python print out full sentences with the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 accounts in my dataset. The last account is 13. In total, the accounts have 14453 followers.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \" + str(demdeb_mar.username.count()) + \n",
    "      \" accounts in my dataset. The last account is \" + str(len(demdeb_mar.username)) + \n",
    "      \". In total, the accounts have \" + str(sum(followers)) + \" followers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4. Adding data to our DataFrame.** Loop through the indices of your `DataFrame`, collect the timeline for each account using the `user_timeline` method from tweepy, and store them in a new list \"timelines\". Note that you will want to build in some `sleep` time to avoid running into rate limits. You can find the syntax for how to do this on page 155 and the logic and examples on pages 209-12 in Brooker (2020)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n",
      "loop\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "timelines = []\n",
    "\n",
    "for n in demdeb_mar.index:\n",
    "    a = api.user_timeline(demdeb_mar.username[n])\n",
    "    timelines.append(a)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    print(\"loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your list \"timelines\" to your current `DataFame`. To do this, we first need to turn our list into a new `DateFrame` with one column labeled `timelines` and then join our two `DateFrames` horizontally, i.e. along `axis = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelines_ = pd.DataFrame({\"timelines\": timelines})\n",
    "demdeb_mar_tl = pd.concat([demdeb_mar, timelines_], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a deep breath. This was a major piece of coding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the timeline, that is the statuses, for each of your accounts in the `DataFrame`. But these are still in the raw format which the Twitter API returns, so we need to transform them into a format that allows us to to work with them more easily. In the end, we want to get at the the topics and persons our accounts tweet about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5. Getting the tweet texts from the timeline.** Extract the text from the tweets in each account's timeline, combine them into a list, turn the list of lists into a `DataFrame`, and join the new and old `DataFrames`. One way to do this is to 1) create an empty list 'tweets', 2) loop through the indices in your `DataFrame`, 3) for each index/row loop through the timeline, 4) create a temporary list, append the text for each timeline element to that list, then append the temporary list to 'tweets' 5) turn the list into a `DataFrame` and 6) merge the two `DataFrames` horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-83-8c99ca5e7475>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-83-8c99ca5e7475>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    demdeb_mar_tl = pd.concat([demdeb_mar_tl, tl_tweets], axis=1)\u001b[0m\n\u001b[0m                                                                 \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "timeline_tweets=[]\n",
    "\n",
    "for timeline in timelines:    \n",
    "    text = []\n",
    "    text.append(tweet._json[\"text\"])\n",
    "    \n",
    "    timeline_tweets.append(text)\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "timeline_tweets=[]\n",
    "\n",
    "for i in demdeb_mar_tl.index:\n",
    "    tweets_no = len(demdeb_mar_tl.timelines[i])\n",
    "    temp = []\n",
    "    for n in range(0,tweets_no):\n",
    "        temp.append(demdeb_mar_tl.timelines[i][n]._json[\"text\"])\n",
    "\n",
    "    timeline_tweets.append(temp)\n",
    "\n",
    "tl_tweets = pd.DataFrame({\"tweets\":timeline_tweets})\n",
    "\n",
    "demdeb_mar_tl = pd.concat([demdeb_mar_tl, tl_tweets], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6. Turning our list of tweet texts into a long string.** To get a sense of what our accounts usually tweet about, it might be useful to have their tweets in one long string that allows us to easily count the words they use. Create a list that holds the long string of tweets for each user. We can concatenate our list of tweets/strings using the [join](https://docs.python.org/2/library/string.html#string.join) command for which you can find a usage example [here](https://stackoverflow.com/a/493842).\n",
    "\n",
    "Turn the list into a `DataFrame` and merge it with your main `DataFrame` horizontally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-cd059634db68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdemdeb_mar_tl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemdeb_mar_tl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "\n",
    "for i in demdeb_mar_tl.index:\n",
    "    text.append(\" \".join(demdeb_mar_tl[\"tweets\"][i]))\n",
    "    \n",
    "    \n",
    "text = pd.DataFrame({\"text\": text})\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7. Finding hashtags and mentions.** Now that we have all the tweets for each account in one long string, we can start looking at the topics the accounts are tweeting about and who they are interacting with. To do so, you can use the [`findall`](https://docs.python.org/3/library/re.html#re.findall) function from the `re` package to extract all hashtags (starting with a \"#\") and mentions (starting with an \"@\"). Add one column for hashtags and mentions respectively to your `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8. Writing your insights to a file.** You have just generated some really awesome insights about the accounts you identified earlier. To share your insights, that is the topics/hashtags your accounts tweet about, you should now write the hashtags to a text file–if you want to remind yourself, we covered this in week 3 day 1. Can you make it so the text file first lists the name and then the hashtags the account uses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9. Descriptive statistics about your accounts.** We closed last week with talking about descriptive statistics. For the accounts you gathered, there are at least three variables that you might be interested to know more about. What are the minimum, maximum, and mean for the number of followers, friends, and posted statuses in you data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10. Visualizing influence.** To round off this exercise, let's plot some data from the accounts you collected. Make a bar plot to show which of the accounts has the most influence on Twitter. _Hint:_ You might want to look at `followers_count`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11. Understanding influence.** Now that you know who is most influential among your accounts, try to see if the data you get from Twitter allows you to explore what might explain that influence. Look into your data and plot the follower count against another variable. Is there a pattern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THERE IS ALWAYS MORE.** If you got all the way through this exercise and are still hungry for more, here are some suggestions for other things you could do:\n",
    "\n",
    "1. To get an even better sense of what your accounts tweet about than just using hashtags, you could count the most used words. Create a list that, for each account has a dictionary of the frequency of each word with stop words removed. Remember, you can reuse your code from W3D1. You can get a list of stop words from [here](http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words). These are also stored in `stop_words.txt`. Add a column to your dataframe for most used words. \n",
    "2. Extract the number of favorites and retweets from the timelines you gathered. Is there any relationship between the number of followers and these figures? How about between these figures and the number of friends?\n",
    "3. Researchers often use Twitter because we can do respondent-driven sampling, i.e. we start with a few accounts and then collect the accounts that follow these accounts to get a broader picture of the network. Start exploring the networks of the accounts you collected using the [`followers`](https://tweepy.readthedocs.io/en/latest/api.html#API.followers) command.\n",
    "4. Given that the accounts you collected are similar in that they tweet about your topic of choice, it might be interesting know if there are issues that distinguish the accounts. Researchers often use term frequency-inverse document frequency to study such differences. [Here](https://www.freecodecamp.org/news/how-to-process-textual-data-using-tf-idf-in-python-cd2bbc0a94a3/) is a primer on the concept and a tutorial on how to implement it in Python. Can you find distinguishes your accounts from one another?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
